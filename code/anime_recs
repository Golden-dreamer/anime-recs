#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Mar  8 09:30:59 2021

@author: leo
"""
import pandas as pd
from Recommender.Algorithm import Recommender
from sklearn.metrics import mean_absolute_error, mean_squared_error
import seaborn as sns
import numpy as np
from sklearn.model_selection import train_test_split



control_group = [7674,5630,395,37520,457,2418,34565,37517,6,16201,31240]

PATH_MY_CORR = '../data/anime/my_corr.csv'
PATH_RATINGS = '../data/anime/ratings.csv'
PATH_MY_RATINGS = '../data/anime/my_rating.xlsx'
PATH_REPLACED_RATINGS = '../data/anime/replaced_ratings.csv'

def get_users_ratings(drop_few_watches=True, n_watched=25):
    columns = ['user', 'item', 'rating']
    ratings = pd.read_csv(PATH_RATINGS, usecols=columns)
    ratings.columns = ['user', 'item', 'rating']    
    if not drop_few_watches:
        return ratings
    #drop users watched  too few anime
    TOTAL_WATCHED_ITEMS = n_watched
    user_counts = ratings.user.value_counts()
    ratings = ratings[~ratings.user.isin(
        user_counts[user_counts < TOTAL_WATCHED_ITEMS].index)]

    return ratings

def get_my_ratings():    
    cols = ['anime_id', 'rating']
    my_ratings = pd.read_excel(PATH_MY_RATINGS, usecols=cols)
    my_ratings.columns = ['item', 'rating']
    
    my_ratings.dropna(inplace=True)
    #my_ratings = my_ratings.loc[~(my_ratings.rating == 1)]    
    return my_ratings

def get_titles():
    cols = ['anime_id','title']
    titles = pd.read_excel(PATH_MY_RATINGS, usecols=cols)
    titles.columns = ['item','title']
    return titles


#weights = pd.read_csv(PATH_MY_CORR ,index_col=0,squeeze = True)



def drop_users_with_too_many_items(data,too_many_items=500):
    items_count_by_user = data.groupby('user',as_index=False)['item'].count()
    heavy_users = items_count_by_user [items_count_by_user .item > too_many_items].user
    data_refined = data.loc[~data.user.isin(heavy_users)]
    return data_refined


def drop_users_with_high_proportion_of_ratings(data,threshold=0.9,
                                               positive_idx=[7,8,9,10]):
    user_rate_count = data.groupby('user')['rating'].value_counts()
    user_rate_count.name = 'rate_count'
    items_total_count = data.groupby('user')['item'].count()
    
    users_rate_proportion = user_rate_count / items_total_count
    positive_rate_per_user_proportion = users_rate_proportion.loc[:,positive_idx].groupby('user').sum()
    users_think_every_item_is_good = positive_rate_per_user_proportion[positive_rate_per_user_proportion > threshold].index
    data_without_happy_users = data[~data.user.isin(users_think_every_item_is_good )]
    return data_without_happy_users 


def replace_rating_with_0_and_1(data):
    new_data = data.copy(deep=True)
    new_data.loc[new_data['rating'] < 6, 'rating'] = 0
    new_data.loc[new_data['rating'] > 5, 'rating'] = 1
    return new_data

def split_df(df, test_samples=6, seed=42):
    np.random.seed(seed)
    data = df.sample(frac=1.0)
    test = data.groupby('user',as_index=False).nth([range(test_samples)])
    train = data.loc[data.index.difference(test.index)]
    return train, test


# -1 is me, Mario!
MY_USER_ID = -1


ratings = get_users_ratings()
anime_titles = get_titles()
my_ratings = get_my_ratings()

df_anime = pd.read_csv('../data/anime/AnimeList.csv')
# ratings_with_me = ratings.append(my_ratings).fillna(MY_USER_ID )

too_many_items = 500
# data_refined = drop_users_with_too_many_items(ratings_with_me, too_many_items)

# data_without_happy_users  = drop_users_with_high_proportion_of_ratings(data_refined)
    
# data_check = replace_rating_with_0_and_1(data_without_happy_users)

data = pd.read_csv(PATH_REPLACED_RATINGS, usecols=['user','item','rating']) 

df_anime.genre = df_anime.genre.str.lower()
df_anime.genre = df_anime.genre.str.strip()
items_e = df_anime[(df_anime.genre.str.contains('ecchi')) > 0]['anime_id']

ecchi_df = ratings[ratings.item.isin(items_e)]
bad_users_e = ecchi_df[ecchi_df.rating > 5].user.unique()
no_ecchi = ratings[~ratings.user.isin(bad_users_e)]

#without_ecchi = ratings[~ratings.item.isin(items_e)]
items_h = df_anime[(df_anime.genre.str.contains('hentai')) > 0]['anime_id']

hentai = ratings[ratings.item.isin(items_h)]
bad_users_h = hentai[hentai.rating > 5].user.unique()

virginity = no_ecchi[~no_ecchi.user.isin(bad_users_h)]
#no_ecchi_hentai = without_ecchi[~without_ecchi.item.isin(items_h)]

data = virginity 
data_with_me = data.append(my_ratings).fillna(MY_USER_ID )
data = drop_users_with_too_many_items(data_with_me , too_many_items)
data = drop_users_with_high_proportion_of_ratings(data)
data = replace_rating_with_0_and_1(data)

#train, test = split_df(data)
user = -1
#user = 5035
min_items = 30

#alg = Recommender(train , user, min_items=min_items,titles=anime_titles)
#alg = Recommender(data, user, min_items=min_items,titles=anime_titles)
k_nn = 50
t = 0.75

#t,p,n = alg.recs(control_group)

#31240
def score_error(train, test, k_users=50):
     #df = df.sample(frac=1.0)
     users = test.user.unique()
     users = users[:len(users)//10000] # reduce calculations
     global_mae = 0
     n = 0
     for user in users:
         min_items = 30
         model = Recommender(train, user, min_items)
         t,p,neg = model.recs(test[test.user == user].item,k_users,0.75)
         true_result = test[test.user == user].set_index('item')['rating']
         items= [el[0] for el in t]
         vals = [el[1] for el in t]
         actual_result = pd.Series(vals, index=items)
         mae = mean_absolute_error(actual_result, true_result)
         print(mae)
         global_mae +=mae
         n = n + 1
     res = global_mae / n
         
     print(f'total misses: {res}')
         


